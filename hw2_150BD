I noticed that Elizabeth DeYong and Shirish Pokharel both mentioned compiling data via Twitter. I think Twitter is a great source for information and it came up in my Big Data research too. One problem with Twitter is that the information is not completely structured so it can be difficult to read. Furthermore, it is difficult to get the sentiment of a tweet, as Elizabeth mentioned in her research. One solution could involve more structured rules for Twitter which would make it easier to sort through the data. However, this could lead to less users and less activity if people did not like being shoeboxed into an exact type of structure to share their thoughts. 

I really enjoyed seeing Shirish's graph, 'Nepali's on Twitter'. It made me think of all the cool trends that could be pulled by compiling all tweets and storing them. During Professor Couch's talk he mentioned that Twitter is not concerned with storing its data long-term because it is more concered with the present flow of data and keeping that flow active. It would be very interesting if someone stored all Twitter data and revisited it 20 or 30 years later to pull out trends or snippets of real-time and real-life opinions from users in the present era. The problem with this is that storing all that data is extremely expensive. It is a shame that we are not storing all this rich data. Who knows what use it could have in the future?

Stefan Dimitrov shared a link about a company, Hampton Creek, that is using Big Data to develop cheap and healthy food. The potential for this project is really excited and could have huge implications for world hungry. One problem that Hampton Creek faces is the pure number of Proteins (~18 billion plant proteins) is so large. They could store all of that data but the downsize is that the storage would be incredibly costly.   